
'''
request为了增加请求部分的内容
可以用来设置请求头
    有一些网站是设置了反爬虫机制,如果没有请求头信息,就无法获取到有价值的网页,因此设置请求头是有必要的
'''

'''有一些网站设置反爬虫机制,原理是基于有些网页是只能从上一个网页跳到此网页中的,所以他访问到此网页的时候会检查一下
上个网页的地址是不是实际地址,所以设置headers 中的 Referer参数是有必要的
'''

'''很过网站会记录你ip某一时间段的访问次数(通过流量统计,系统日志),如果访问次数多的不想正常人,他会禁止这个ip访问(加入黑名单)
因此,可以通过设置一些代理服务器(ProxyHandler是一个代理ip的服务器),每隔一段时间换一个代理,这样就算ip被禁止了,也可以换一个ip继续爬
'''
'''
很过网站会记录你ip某一时间段的访问次数(通过流量统计,系统日志),如果访问次数多的不想正常人,他会禁止这个ip访问(加入黑名单,或者提示你操作太频繁了)
这时候你可以用上面的方法,也可以在每次请求前等待一小段时间

'''

'''获取一个网页的信息一般采用的get请求,但是一些网站为了防止爬虫,将一些本应该用get请求获得网页
请求方式改成post,因此值得注意
'''

